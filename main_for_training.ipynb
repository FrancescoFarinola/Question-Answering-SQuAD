{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219b4988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\userl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow import one_hot\n",
    "import load_data\n",
    "import preprocess\n",
    "import utils\n",
    "import drqa_model\n",
    "import bidaf_model\n",
    "import our_model\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "\n",
    "from os.path import isfile\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json \n",
    "from settings import EMBEDDING_DIM, MODEL, EPOCHS, BATCH_SIZE, MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3d4722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "(87599, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "dataframe = load_data.load_dataset()\n",
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34761949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train and test set...\n",
      "(78161, 6) (9438, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting train and test set...\")\n",
    "train_df, test_df = load_data.split_test_set(dataframe)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bd3ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train and validation set...\n",
      "(61143, 6) (17018, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting train and validation set...\")\n",
    "train_df, val_df = load_data.split_validation_set(train_df, rate=0.2)\n",
    "print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c9dbf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n",
      "Preprocessing validation data...\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_PIPELINE1 = [preprocess.expand_contractions,\n",
    "                           preprocess.tokenization_spacy,\n",
    "                           preprocess.remove_chars,\n",
    "                           preprocess.split_alpha_num_sym,\n",
    "                           preprocess.spell_correction,\n",
    "                           preprocess.lemmatization,\n",
    "                           preprocess.lower,\n",
    "                           preprocess.strip_text]\n",
    "\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df1 = train_df.copy()\n",
    "train_df1, train_tmp1 = preprocess.apply_preprocessing(train_df1, PREPROCESSING_PIPELINE1)\n",
    "\n",
    "print(\"Preprocessing validation data...\")\n",
    "val_df1 = val_df.copy()\n",
    "val_df1, val_tmp1 = preprocess.apply_preprocessing(val_df1, PREPROCESSING_PIPELINE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c4c1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\userl\\\\Documents\\\\GitHub\\\\FFSquad\\\\utils.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import importlib\n",
    "#importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32502566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load: False\n",
      "Computing matrices, tokenizers and dictionaries... \n",
      "Loading GloVe embedding model...\n",
      "There are 53939 words for which we already know the embedding\n",
      "There are 11303 oov words\n",
      "Computing out-of-vocabulary embeddings...\n",
      "Computing embedding matrix...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# load already saved content or compute it from scratch\n",
    "load = (isfile(f\"{MODELS_DIR}/word_listing.csv\") and \n",
    "        isfile(f\"{MODELS_DIR}/word2idx.json\") and\n",
    "        isfile(f\"{MODELS_DIR}/idx2word.json\") and\n",
    "        isfile(f\"{MODELS_DIR}/tokenizer.json\") and\n",
    "        isfile(f\"{MODELS_DIR}/embedding_matrix.csv\") and\n",
    "        # char embedding matrix is loaded only in case of 'our_model' or 'bidaf'\n",
    "        (not(MODEL == \"our_model\" or MODEL == 'bidaf') or\n",
    "         isfile(f\"{MODELS_DIR}/char_embedding_matrix.csv\")))\n",
    "print(\"load:\", load)\n",
    "\n",
    "if load:\n",
    "    print(\"Loading matrices, tokenizers and dictionaries... \")\n",
    "    #load pre-saved \n",
    "    df_word_listing = np.genfromtxt(f\"{MODELS_DIR}/word_listing.csv\", delimiter=',', encoding='utf-8', dtype='str')\n",
    "    \n",
    "    with open(f\"{MODELS_DIR}/word2idx.json\") as f:\n",
    "        df_word_to_idx = json.load(f)\n",
    "\n",
    "    with open(f\"{MODELS_DIR}/idx2word.json\") as f:\n",
    "        df_idx_to_word = json.load(f)\n",
    "\n",
    "    with open(f\"{MODELS_DIR}/tokenizer.json\") as f:\n",
    "        tokenizer_json = json.load(f)\n",
    "        df_tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "\n",
    "    embedding_matrix = np.genfromtxt(f\"{MODELS_DIR}/embedding_matrix.csv\", delimiter=',')\n",
    "    print(\"Done\")\n",
    "          \n",
    "else:\n",
    "    #compute \n",
    "    print(\"Computing matrices, tokenizers and dictionaries... \")\n",
    "    embedding_matrix, df_word_listing, df_tokenizer, df_word_to_idx, df_idx_to_word = utils.get_embedding_matrix(train_df1, EMBEDDING_DIM)\n",
    "    \n",
    "    np.savetxt(f\"{MODELS_DIR}/embedding_matrix.csv\", embedding_matrix, delimiter=\",\")\n",
    "    np.savetxt(f\"{MODELS_DIR}/word_listing.csv\", df_word_listing, delimiter=\",\", fmt =\"%s\", encoding='utf-8')\n",
    "\n",
    "    with open(f\"{MODELS_DIR}/word2idx.json\", 'w') as f:\n",
    "        json.dump(df_word_to_idx, f)\n",
    "\n",
    "    with open(f\"{MODELS_DIR}/idx2word.json\", 'w') as f:\n",
    "        json.dump(df_idx_to_word, f)\n",
    "\n",
    "    tokenizer_json = df_tokenizer.to_json()\n",
    "    with io.open(f\"{MODELS_DIR}/tokenizer.json\", 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10996e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idx_to_word = dict(zip([int(k) for k in df_idx_to_word.keys()], df_idx_to_word.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c009329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length for context is 662\n",
      "Max length adopted for context is 728\n",
      "Max length for answer is 43\n",
      "Max length adopted for answer is 47\n",
      "Max length for question is 40\n",
      "Max length adopted for question is 44\n",
      "Padding data...\n"
     ]
    }
   ],
   "source": [
    "MAX_CONTEXT_LENGTH, MAX_TEXT_LENGTH, MAX_QUESTION_LENGTH = utils.get_max_length(train_df1)\n",
    "\n",
    "#MAX_CONTEXT_LENGTH, MAX_TEXT_LENGTH, MAX_QUESTION_LENGTH = 662, 43, 40\n",
    "print(\"Padding data...\")\n",
    "tr_context_padded = utils.pad(train_df1.context, df_tokenizer, MAX_CONTEXT_LENGTH)\n",
    "tr_answer_padded = utils.pad(train_df1.text, df_tokenizer, MAX_TEXT_LENGTH)\n",
    "tr_question_padded = utils.pad(train_df1.question, df_tokenizer, MAX_QUESTION_LENGTH)\n",
    "\n",
    "val_context_padded = utils.pad(val_df1.context, df_tokenizer, MAX_CONTEXT_LENGTH)\n",
    "val_answer_padded = utils.pad(val_df1.text, df_tokenizer, MAX_TEXT_LENGTH)\n",
    "val_question_padded = utils.pad(val_df1.question, df_tokenizer, MAX_QUESTION_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a9ec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing start and end indices... \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing start and end indices... \")\n",
    "train_df1['s_idx'] = train_df.apply(\n",
    "    lambda x: len(preprocess.preprocessing(x.context[:x.answer_start], PREPROCESSING_PIPELINE1).split()), axis=1)\n",
    "train_df1['e_idx'] = train_df1.apply(lambda x: x.s_idx + len(x.text.split()) - 1, axis=1)\n",
    "\n",
    "val_df1['s_idx'] = val_df.apply(\n",
    "    lambda x: len(preprocess.preprocessing(x.context[:x.answer_start], PREPROCESSING_PIPELINE1).split()), axis=1)\n",
    "val_df1['e_idx'] = val_df1.apply(lambda x: x.s_idx + len(x.text.split()) - 1, axis=1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7bf7012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionaries for POS tags...\n",
      "Creating dictionaries for NER tags...\n",
      "Extracting features for Train Set\n",
      "Computing original exact match...\n",
      "Computing lowercase exact match...\n",
      "Computing lemmatized exact match...\n",
      "Computing TF...\n",
      "Computing POS tags...\n",
      "Padding POS sequences...\n",
      "Computing NER tags...\n",
      "Padding NER sequences...\n",
      "Extracting features for Validation Set\n",
      "Computing original exact match...\n",
      "Computing lowercase exact match...\n",
      "Computing lemmatized exact match...\n",
      "Computing TF...\n",
      "Computing POS tags...\n",
      "Padding POS sequences...\n",
      "Computing NER tags...\n",
      "Padding NER sequences...\n",
      "Computing character-level embeddings...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "context (InputLayer)            [(None, 728)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, 44)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "p_encoding (Embedding)          (None, 728, 200)     13048800    context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "char_p_encoding (Embedding)     (None, 728, 50)      3262200     context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q_encoding (Embedding)          (None, 44, 200)      13048800    question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "char_q_encoding (Embedding)     (None, 44, 50)       3262200     question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_p (Concatenate)          (None, 728, 250)     0           p_encoding[0][0]                 \n",
      "                                                                 char_p_encoding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concat_q (Concatenate)          (None, 44, 250)      0           q_encoding[0][0]                 \n",
      "                                                                 char_q_encoding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_p (Dense)                 (None, 728, 200)     50200       concat_p[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_q (Dense)                 (None, 44, 200)      50200       concat_q[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "biH (Bidirectional)             (None, 728, 200)     181200      dense_p[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "biU (Bidirectional)             (None, 44, 200)      181200      dense_q[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "S (SimilarityLayer)             (None, 728, 44)      600         biH[0][0]                        \n",
      "                                                                 biU[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pos (InputLayer)                [(None, 728)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ner (InputLayer)                [(None, 728)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C2Q (C2Q)                       (None, 728, 200)     0           biU[0][0]                        \n",
      "                                                                 S[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "Q2C (Q2C)                       (None, 728, 200)     0           biH[0][0]                        \n",
      "                                                                 S[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "em (InputLayer)                 [(None, 728, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_encoding (Embedding)        (None, 728, 54)      2916        pos[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "ner_encoding (Embedding)        (None, 728, 20)      400         ner[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf (InputLayer)                 [(None, 728, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "G (MergeG)                      (None, 728, 878)     0           biH[0][0]                        \n",
      "                                                                 C2Q[0][0]                        \n",
      "                                                                 Q2C[0][0]                        \n",
      "                                                                 em[0][0]                         \n",
      "                                                                 pos_encoding[0][0]               \n",
      "                                                                 ner_encoding[0][0]               \n",
      "                                                                 tf[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "M (Bidirectional)               (None, 728, 200)     588000      G[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "M2 (Bidirectional)              (None, 728, 200)     181200      M[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "GM (Concatenate)                (None, 728, 1078)    0           G[0][0]                          \n",
      "                                                                 M[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "GM2 (Concatenate)               (None, 728, 1078)    0           G[0][0]                          \n",
      "                                                                 M2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "td_s (TimeDistributed)          (None, 728, 1)       1079        GM[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "td_e (TimeDistributed)          (None, 728, 1)       1079        GM2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 728)          0           td_s[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_1 (TFOpLam (None, 728)          0           td_e[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "start_ (Softmax)                (None, 728)          0           tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "end_ (Softmax)                  (None, 728)          0           tf.compat.v1.squeeze_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Prediction)         (None, 728, 728)     0           start_[0][0]                     \n",
      "                                                                 end_[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "start (Lambda)                  (None, 728)          0           prediction[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "end (Lambda)                    (None, 728)          0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 33,860,074\n",
      "Trainable params: 1,234,758\n",
      "Non-trainable params: 32,625,316\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#save weights instead of saving entire model\n",
    "\n",
    "if MODEL == 'basemodel' or MODEL == None:\n",
    "    pass\n",
    "\n",
    "elif MODEL == 'drqa':\n",
    "    tag2idx, idx2tag = utils.create_pos_dicts()\n",
    "    ner2idx, idx2ner = utils.create_ner_dicts()\n",
    "\n",
    "    pos_embedding_matrix = to_categorical(list(idx2tag.keys()))\n",
    "    ner_embedding_matrix = to_categorical(list(idx2ner.keys()))\n",
    "\n",
    "    print(\"Extracting features for Train Set\")\n",
    "    train_em_input = utils.compute_exact_match(train_df1, MAX_CONTEXT_LENGTH)\n",
    "    train_tf_input = utils.compute_tf(train_df1, MAX_CONTEXT_LENGTH)\n",
    "    train_pos_input = utils.compute_pos(train_df1, tag2idx, MAX_CONTEXT_LENGTH)\n",
    "    train_ner_input = utils.compute_ner(train_df1, ner2idx, MAX_CONTEXT_LENGTH)\n",
    "\n",
    "    print(\"Extracting features for Validation Set\")\n",
    "    val_em_input = utils.compute_exact_match(val_df1, MAX_CONTEXT_LENGTH)\n",
    "    val_tf_input = utils.compute_tf(val_df1, MAX_CONTEXT_LENGTH)\n",
    "    val_pos_input = utils.compute_pos(val_df1, tag2idx, MAX_CONTEXT_LENGTH)\n",
    "    val_ner_input = utils.compute_ner(val_df1, ner2idx, MAX_CONTEXT_LENGTH)\n",
    "\n",
    "\n",
    "    model = drqa_model.build_model(MAX_QUESTION_LENGTH, MAX_CONTEXT_LENGTH, EMBEDDING_DIM, embedding_matrix,\n",
    "                pos_embedding_matrix, ner_embedding_matrix)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics='accuracy')\n",
    "    model.summary()\n",
    "    plot_model(model, rankdir='TB', show_shapes=True, show_dtype=True, to_file=f\"{MODELS_DIR}/drqa.png\")\n",
    "\n",
    "    tr_s_one = one_hot(train_df1.s_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    tr_e_one = one_hot(train_df1.e_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    val_s_one = one_hot(val_df1.s_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    val_e_one = one_hot(val_df1.e_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "\n",
    "    x_tr = {'context': tr_context_padded, 'question': tr_question_padded, 'pos': train_pos_input,\n",
    "            'ner': train_ner_input, 'em': train_em_input, 'tf': train_tf_input}\n",
    "    x_val = {'context': val_context_padded, 'question': val_question_padded, 'pos': val_pos_input,\n",
    "             'ner': val_ner_input, 'em': val_em_input, 'tf': val_tf_input}\n",
    "\n",
    "    y_tr = {'start': tr_s_one, 'end': tr_e_one}\n",
    "    y_val = {'start': val_s_one, 'end': val_e_one}\n",
    "\n",
    "    #mycb = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    #model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[mycb])\n",
    "    #model.save_weights(f\"{MODELS_DIR}/drqa_weights.h5\")\n",
    "\n",
    "elif MODEL == \"bidaf\":\n",
    "\n",
    "    char_embedding_matrix = utils.get_char_embeddings(df_word_listing, df_word_to_idx)\n",
    "\n",
    "    model = bidaf_model.build_model(MAX_QUESTION_LENGTH, MAX_CONTEXT_LENGTH, EMBEDDING_DIM, embedding_matrix, char_embedding_matrix)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics='accuracy')\n",
    "    model.summary()\n",
    "    plot_model(model, rankdir='TB', show_shapes=True, show_dtype=True, to_file=f\"{MODELS_DIR}/bidaf.png\")\n",
    "\n",
    "    tr_s_one = one_hot(train_df1.s_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    tr_e_one = one_hot(train_df1.e_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    val_s_one = one_hot(val_df1.s_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    val_e_one = one_hot(val_df1.e_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "\n",
    "    x_tr = {'context': tr_context_padded, 'question': tr_question_padded}\n",
    "    x_val = {'context': val_context_padded, 'question': val_question_padded}\n",
    "\n",
    "    y_tr = {'start': tr_s_one, 'end': tr_e_one}\n",
    "    y_val = {'start': val_s_one, 'end': val_e_one}\n",
    "\n",
    "    #mycb = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    #model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[mycb])\n",
    "    #model.save(f\"{MODELS_DIR}/bidaf_weights.h5\")\n",
    "\n",
    "elif MODEL == \"our_model\":\n",
    "    tag2idx, idx2tag = utils.create_pos_dicts()\n",
    "    ner2idx, idx2ner = utils.create_ner_dicts()\n",
    "\n",
    "    pos_embedding_matrix = to_categorical(list(idx2tag.keys()))\n",
    "    ner_embedding_matrix = to_categorical(list(idx2ner.keys()))\n",
    "\n",
    "    print(\"Extracting features for Train Set\")\n",
    "    train_em_input = utils.compute_exact_match(train_df1, MAX_CONTEXT_LENGTH)\n",
    "    train_tf_input = utils.compute_tf(train_df1, MAX_CONTEXT_LENGTH)\n",
    "    train_pos_input = utils.compute_pos(train_df1, tag2idx, MAX_CONTEXT_LENGTH)\n",
    "    train_ner_input = utils.compute_ner(train_df1, ner2idx, MAX_CONTEXT_LENGTH)\n",
    "\n",
    "    print(\"Extracting features for Validation Set\")\n",
    "    val_em_input = utils.compute_exact_match(val_df1, MAX_CONTEXT_LENGTH)\n",
    "    val_tf_input = utils.compute_tf(val_df1, MAX_CONTEXT_LENGTH)\n",
    "    val_pos_input = utils.compute_pos(val_df1, tag2idx, MAX_CONTEXT_LENGTH)\n",
    "    val_ner_input = utils.compute_ner(val_df1, ner2idx, MAX_CONTEXT_LENGTH)\n",
    "\n",
    "    if isfile(f\"{MODELS_DIR}/char_embedding_matrix.csv\"):\n",
    "        char_embedding_matrix = np.genfromtxt(f\"{MODELS_DIR}/char_embedding_matrix.csv\", delimiter=',')\n",
    "    else:\n",
    "        char_embedding_matrix = utils.get_char_embeddings(df_word_listing, df_word_to_idx)\n",
    "        np.savetxt(f\"{MODELS_DIR}/char_embedding_matrix.csv\", char_embedding_matrix, delimiter=\",\")\n",
    "\n",
    "    model = our_model.build_model(MAX_QUESTION_LENGTH, MAX_CONTEXT_LENGTH, EMBEDDING_DIM,\n",
    "                                  embedding_matrix, char_embedding_matrix, pos_embedding_matrix, ner_embedding_matrix)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics='accuracy')\n",
    "    model.summary()\n",
    "    plot_model(model, rankdir='TB', show_shapes=True, show_dtype=True, to_file=f\"{MODELS_DIR}/our_model.png\")\n",
    "\n",
    "    tr_s_one = one_hot(train_df1.s_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    tr_e_one = one_hot(train_df1.e_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    val_s_one = one_hot(val_df1.s_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "    val_e_one = one_hot(val_df1.e_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "\n",
    "    x_tr = {'context': tr_context_padded, 'question': tr_question_padded, 'pos': train_pos_input,\n",
    "            'ner': train_ner_input, 'em': train_em_input, 'tf': train_tf_input}\n",
    "    x_val = {'context': val_context_padded, 'question': val_question_padded, 'pos': val_pos_input,\n",
    "             'ner': val_ner_input, 'em': val_em_input, 'tf': val_tf_input}\n",
    "\n",
    "    y_tr = {'start': tr_s_one, 'end': tr_e_one}\n",
    "    y_val = {'start': val_s_one, 'end': val_e_one}\n",
    "\n",
    "    #mycb = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    #model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[mycb])\n",
    "    #model.save_weights(f\"{MODELS_DIR}/our_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e382cea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'our_model' from 'C:\\\\Users\\\\userl\\\\Documents\\\\GitHub\\\\FFSquad\\\\our_model.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import importlib\n",
    "#importlib.reload(our_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48a9a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "context (InputLayer)            [(None, 728)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, 44)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "p_encoding (Embedding)          (None, 728, 200)     13048800    context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "char_p_encoding (Embedding)     (None, 728, 50)      3262200     context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q_encoding (Embedding)          (None, 44, 200)      13048800    question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "char_q_encoding (Embedding)     (None, 44, 50)       3262200     question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_p (Concatenate)          (None, 728, 250)     0           p_encoding[0][0]                 \n",
      "                                                                 char_p_encoding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concat_q (Concatenate)          (None, 44, 250)      0           q_encoding[0][0]                 \n",
      "                                                                 char_q_encoding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_p (Dense)                 (None, 728, 100)     25100       concat_p[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_q (Dense)                 (None, 44, 100)      25100       concat_q[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "biH (Bidirectional)             (None, 728, 100)     45600       dense_p[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "biU (Bidirectional)             (None, 44, 100)      45600       dense_q[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "S (SimilarityLayer)             (None, 728, 44)      300         biH[0][0]                        \n",
      "                                                                 biU[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "pos (InputLayer)                [(None, 728)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ner (InputLayer)                [(None, 728)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C2Q (C2Q)                       (None, 728, 100)     0           biU[0][0]                        \n",
      "                                                                 S[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "Q2C (Q2C)                       (None, 728, 100)     0           biH[0][0]                        \n",
      "                                                                 S[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "em (InputLayer)                 [(None, 728, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_encoding (Embedding)        (None, 728, 54)      2916        pos[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "ner_encoding (Embedding)        (None, 728, 20)      400         ner[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf (InputLayer)                 [(None, 728, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "G (MergeG)                      (None, 728, 478)     0           biH[0][0]                        \n",
      "                                                                 C2Q[0][0]                        \n",
      "                                                                 Q2C[0][0]                        \n",
      "                                                                 em[0][0]                         \n",
      "                                                                 pos_encoding[0][0]               \n",
      "                                                                 ner_encoding[0][0]               \n",
      "                                                                 tf[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "M (Bidirectional)               (None, 728, 100)     159000      G[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "M2 (Bidirectional)              (None, 728, 100)     45600       M[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "GM (Concatenate)                (None, 728, 578)     0           G[0][0]                          \n",
      "                                                                 M[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "GM2 (Concatenate)               (None, 728, 578)     0           G[0][0]                          \n",
      "                                                                 M2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "td_s (TimeDistributed)          (None, 728, 1)       579         GM[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "td_e (TimeDistributed)          (None, 728, 1)       579         GM2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_4 (TFOpLam (None, 728)          0           td_s[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_5 (TFOpLam (None, 728)          0           td_e[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "start_ (Softmax)                (None, 728)          0           tf.compat.v1.squeeze_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "end_ (Softmax)                  (None, 728)          0           tf.compat.v1.squeeze_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Prediction)         (None, 728, 728)     0           start_[0][0]                     \n",
      "                                                                 end_[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "start (Lambda)                  (None, 728)          0           prediction[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "end (Lambda)                    (None, 728)          0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 32,972,774\n",
      "Trainable params: 347,458\n",
      "Non-trainable params: 32,625,316\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3822/3822 [==============================] - 911s 234ms/step - loss: 5.3123 - start_loss: 2.7792 - end_loss: 2.5331 - start_accuracy: 0.3235 - end_accuracy: 0.3470 - val_loss: 4.3422 - val_start_loss: 2.2946 - val_end_loss: 2.0477 - val_start_accuracy: 0.4030 - val_end_accuracy: 0.4446\n"
     ]
    }
   ],
   "source": [
    "model = our_model.build_model(MAX_QUESTION_LENGTH, MAX_CONTEXT_LENGTH, EMBEDDING_DIM,\n",
    "                                  embedding_matrix, char_embedding_matrix, pos_embedding_matrix, ner_embedding_matrix)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics='accuracy')\n",
    "model.summary()\n",
    "plot_model(model, rankdir='TB', show_shapes=True, show_dtype=True, to_file=f\"{MODELS_DIR}/our_model.png\")\n",
    "\n",
    "\n",
    "mycb = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=1, batch_size=BATCH_SIZE, callbacks=[mycb])\n",
    "model.save_weights(f\"{MODELS_DIR}/{MODEL}_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "815286ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2565/3822 [===================>..........] - ETA: 4:37 - loss: 4.3248 - start_loss: 2.2849 - end_loss: 2.0399 - start_accuracy: 0.4143 - end_accuracy: 0.4489"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1448/2535980827.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#2nd epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmycb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\qa_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qa_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qa_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qa_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qa_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qa_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\qa_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#2nd epoch\n",
    "model.fit(x_tr, y_tr, validation_data=(x_val, y_val), epochs=1, batch_size=BATCH_SIZE, callbacks=[mycb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights(f\"{MODELS_DIR}/{MODEL}_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = test_df.copy()\n",
    "test_df1, test_tmp1 = preprocess.apply_preprocessing(test_df1, PREPROCESSING_PIPELINE1)\n",
    "\n",
    "ts_context_padded = utils.pad(test_df1.context, df_tokenizer, MAX_CONTEXT_LENGTH)\n",
    "ts_answer_padded = utils.pad(test_df1.text, df_tokenizer, MAX_TEXT_LENGTH)\n",
    "ts_question_padded = utils.pad(test_df1.question, df_tokenizer, MAX_QUESTION_LENGTH)\n",
    "\n",
    "test_df1['s_idx'] = test_df.apply(\n",
    "    lambda x: len(preprocess.preprocessing(x.context[:x.answer_start], PREPROCESSING_PIPELINE1).split()), axis=1)\n",
    "test_df1['e_idx'] = test_df1.apply(lambda x: x.s_idx + len(x.text.split()) - 1, axis=1)\n",
    "\n",
    "ts_s_one = one_hot(test_df1.s_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "ts_e_one = one_hot(test_df1.e_idx, depth=MAX_CONTEXT_LENGTH)\n",
    "\n",
    "if MODEL == 'drqa' or MODEL == \"our_model\":\n",
    "\n",
    "    ts_em_input = utils.compute_exact_match(test_df1, MAX_CONTEXT_LENGTH)\n",
    "    ts_tf_input = utils.compute_tf(test_df1, MAX_CONTEXT_LENGTH)\n",
    "    ts_pos_input = utils.compute_pos(test_df1, tag2idx, MAX_CONTEXT_LENGTH)\n",
    "    ts_ner_input = utils.compute_ner(test_df1, ner2idx, MAX_CONTEXT_LENGTH)\n",
    "\n",
    "    x_ts = {'context': ts_context_padded, 'question': ts_question_padded, 'pos': ts_pos_input,\n",
    "            'ner': ts_ner_input, 'em': ts_em_input, 'tf': ts_tf_input}\n",
    "    y_ts = {'start': ts_s_one, 'end': ts_e_one}\n",
    "else:\n",
    "    x_ts = {'context': ts_context_padded, 'question': ts_question_padded}\n",
    "    y_ts = {'start': ts_s_one, 'end': ts_e_one}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evalutating model...\")\n",
    "evaluation = model.evaluate(x_ts, y_ts, batch_size=BATCH_SIZE)\n",
    "print(evaluation)\n",
    "\n",
    "\n",
    "df = pd.concat([train_df, val_df, test_df], 0, ignore_index=True)\n",
    "x = {**x_tr, **x_val, **x_ts}\n",
    "predictions = utils.computing_predictions(model, df, x, BATCH_SIZE)\n",
    "\n",
    "#predictions = utils.computing_predictions(model, train_df, val_df, test_df, x_tr, x_val, x_ts)\n",
    "\n",
    "print(\"Saving predictions as json...\")\n",
    "with open('predictions.json', 'w') as outfile:\n",
    "    json.dump(predictions, outfile)\n",
    "\n",
    "f1, precision, recall = utils.evaluate_model(model, MAX_CONTEXT_LENGTH, val_df1, x_val)\n",
    "print(f\"F1: {f1}\\t Precision: {precision}\\t Recall: {recall}\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bd2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
